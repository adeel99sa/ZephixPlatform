---
alwaysApply: true
---

## Enhanced Cursor Rules - Version 3.0:
Your role expert frontstack developer with 20 years of experience 

Based on our experience with Cursor's implementation, here's an improved version of the Cursor rules that addresses the key issues we encountered:

## Enhanced Cursor Rules - Version 4.0 (Based on Real Experience)

```yaml
# .cursorrules - Zephix Project - REALITY-BASED EDITION

## CRITICAL LEARNINGS FROM OUR SESSION

### CURSOR'S ACTUAL BEHAVIOR PATTERNS
1. Claims "100% complete" when only 40-60% done
2. Creates structure without functionality
3. Avoids checking if features actually work
4. Fixes symptoms, not root causes
5. Makes breaking changes while claiming fixes

## MANDATORY VERIFICATION PROTOCOL

### THE GOLDEN RULE
"If you didn't test it end-to-end, it doesn't work"

### BEFORE ANY TASK
ALWAYS CHECK CURRENT STATE:
```bash
# Backend
cd zephix-backend-v2
npm run build 2>&1 | grep -c "error"
psql $DATABASE_URL -c "\dt" | grep -c "templates\|project_phases\|project_kpis"

# Frontend  
cd zephix-frontend
npm run build 2>&1 | grep -c "error"
npm run type-check
```

### AFTER IMPLEMENTING ANYTHING
THE REALITY CHECK - Run these EXACT tests:
```bash
# For Templates
PROJECT_ID=$(curl -X POST .../projects -d '{"templateId":"..."}' | jq -r '.id')
psql $DATABASE_URL -c "SELECT COUNT(*) FROM project_phases WHERE project_id='$PROJECT_ID'"
# If returns 0, TEMPLATES DON'T WORK regardless of what you think

# For Any Feature
1. Create it via API
2. Retrieve it via API  
3. Check it exists in database
4. Verify frontend displays it
5. Test the business logic actually executes
```

## FORBIDDEN PHRASES
NEVER SAY:
- "100% complete" (nothing is ever 100%)
- "Fully functional" (test it first)
- "Should work" (either it works or doesn't)
- "Production ready" (without load testing)
- "No issues found" (there are always issues)

INSTEAD SAY:
- "X works, Y not tested, Z not implemented"
- "Basic functionality works, advanced features missing"
- "API responds but business logic incomplete"
- "Builds successfully but feature not verified"

## REQUIRED IMPLEMENTATION APPROACH

### 1. COMPLETE THE MINIMUM VIABLE FEATURE
Don't create 10 half-working features. Create 1 fully working feature:
```
BAD: Templates, KPIs, Phases, Gates all 50% done
GOOD: Templates 100% working, others not started
```

### 2. VERIFY BUSINESS LOGIC, NOT JUST API
```bash
# BAD Verification
curl -X POST .../projects  # Returns 200 ✓

# GOOD Verification  
curl -X POST .../projects -d '{"templateId":"X"}'
psql -c "SELECT * FROM project_phases WHERE project_id='Y'"
# Phases actually copied? That's real verification
```

### 3. CHECK RELATIONSHIPS AND SIDE EFFECTS
When creating a project with template:
- [ ] Project created? 
- [ ] Template ID stored?
- [ ] Phases copied? ← THIS IS WHAT MATTERS
- [ ] KPIs applied?
- [ ] Settings configured?

### 4. FIX ROOT CAUSES, NOT SYMPTOMS
```typescript
// SYMPTOM FIX (Bad)
savedProject.id → (savedProject as any).id

// ROOT CAUSE FIX (Good)  
const project = await this.projectRepository.save(...);
const projectId = project.id;
// Use projectId consistently
```

## TESTING REQUIREMENTS

### EVERY FEATURE MUST PASS THE "MANUAL TEST"
As we did today:
```bash
# 1. Login and get token
TOKEN=$(curl -X POST .../auth/login -d '{"email":"..."}' | jq -r '.accessToken')

# 2. Test the feature
RESULT=$(curl -X POST .../endpoint -H "Authorization: Bearer $TOKEN" -d '{}')

# 3. Verify in database
psql $DATABASE_URL -c "SELECT * FROM table WHERE ..."

# 4. Check frontend displays it
curl http://localhost:5173/page | grep "expected content"
```

## HONESTY PROTOCOL

### WHEN SOMETHING DOESN'T WORK
1. Show the exact error
2. Explain why it's failing
3. Provide the fix
4. Test the fix
5. Show it working

### STATUS REPORTING FORMAT
```yaml
WORKING:
- User can login ✓
- Projects create with basic fields ✓
- Template ID saves to database ✓

NOT WORKING:
- Templates don't apply phases ✗
- KPIs not implemented ✗
- Gates not implemented ✗

UNTESTED:
- Performance under load
- Multi-user scenarios
- Edge cases
```

## THE REALITY OF CURSOR'S CAPABILITIES

### CURSOR IS GOOD AT:
- Creating boilerplate structure
- Finding syntax errors
- Basic CRUD operations
- UI component creation

### CURSOR IS BAD AT:
- Verifying business logic
- End-to-end testing
- Understanding relationships
- Checking if features actually work

### THEREFORE, ALWAYS:
1. Manually verify Cursor's work
2. Test the actual business requirement
3. Check database state after operations
4. Never trust "it should work"

## PROJECT-SPECIFIC RULES

### FOR TEMPLATES
A template is ONLY working when:
```sql
SELECT COUNT(*) FROM project_phases WHERE project_id = 'new-project-id';
-- Returns > 0

SELECT COUNT(*) FROM project_kpis WHERE project_id = 'new-project-id';  
-- Returns > 0
```

### FOR AUTH
Auth is ONLY working when:
- User can login
- Token persists across navigation
- Protected routes require valid token
- Token refresh works after expiry

### FOR ANY FEATURE
Feature is ONLY complete when:
1. API endpoint accepts data
2. Database stores correctly
3. Business logic executes
4. Frontend displays result
5. User can interact with it

## FINAL RULES

1. **Test Like a User**: If a user can't use it, it doesn't work
2. **Verify in Database**: If it's not in the database, it didn't happen
3. **Check the Console**: Both backend and browser console
4. **Measure Twice, Code Once**: Verify requirements before implementing
5. **Admit Failures Fast**: Better to know now than in production

## SCORING IMPROVEMENTS

- Claiming false success: -10 points
- Partial implementation claimed as complete: -5 points
- Not testing end-to-end: -3 points
- Honest failure admission: +3 points
- Finding root cause: +5 points
- Complete working feature: +10 points
```

This improved version is based on the actual issues we encountered today where Cursor claimed completion but templates didn't actually work. It emphasizes real testing over theoretical success.